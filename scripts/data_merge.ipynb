{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe007551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e135686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../extra_data/Task Ratings 20.1.xlsx\")\n",
    "df.to_csv(\"../extra_data/Task Ratings 20.1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf199775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks in both: 18427\n",
      "Tasks only in new: 0\n",
      "Tasks only in Claude's set: 0\n",
      "Claude % tasks (unique): 3514\n",
      "In both (mapped % task exists in NEW): 3513\n",
      "Missing in NEW (mapped % task not found): 1\n",
      "Coverage (% of Claude % tasks found in NEW): 99.97 %\n",
      "\n",
      "Sample missing tasks: ['none']\n",
      "Sum of pct for missing tasks: 0.4815572435538299\n",
      "Percent of total pct from missing tasks: 0.48%\n",
      "\n",
      "--- Ratings File Checks ---\n",
      "Task statements in ratings: 17808 / 18427 (96.64%)\n",
      "Task statements missing in ratings: 619\n",
      "Sample missing from ratings (statements): ['adjust network sizes to meet volume or capacity demands', 'adjust temperature  pressure  vacuum  level  flow rate  or transfer of biofuels to maintain processes at required levels', 'administer tests to help determine children s developmental levels  needs  or potential', 'advise clients on aspects of capitalization  such as amounts  sources  or timing', 'advise farmers on upgrading global positioning system  gps  equipment to take advantage of newly installed advanced satellite technology', 'advise technical professionals on the development or use of environmental compliance or reporting tools', 'alert constituents of government actions and programs by way of newsletters  personal appearances at town meetings  phone calls  and individual meetings', 'analyze and evaluate energy supply bids to determine the best options', 'analyze and understand the local and national implications of proposed legislation', 'analyze energy requirements and distribution systems to maximize the use of intermittent or inflexible renewable energy sources  such as wind or nuclear']\n",
      "\n",
      "Task mappings in ratings: 3393 / 3514 (96.56%)\n",
      "Task mappings missing in ratings: 121\n",
      "Sample missing from ratings (mappings): ['analyze energy requirements and distribution systems to maximize the use of intermittent or inflexible renewable energy sources  such as wind or nuclear', 'analyze financial or operational performance of companies facing financial difficulties to identify or recommend remedies', 'analyze green product marketing or sales trends to forecast future conditions', 'analyze regional energy markets  including energy pricing  market structures  energy generation competition  and energy transmission constraints', 'analyze test data for automotive systems  subsystems  or component parts', 'analyze the effectiveness of marketing tactics or channels', 'analyze the layout  instrumentation  or function of electrical generation or transmission facilities', 'apply mathematical or statistical techniques to address practical issues in finance  such as derivative valuation  securities trading  risk management  or financial market regulation', 'arrange financing of deals from sources such as financial institutions  agencies  or public or private companies', 'assist engineers to design or develop electrochemical devices  such as solid oxide membranes or other products for sustainable applications']\n",
      "\n",
      "Sum of pct for missing mappings: 3.781839976026365\n",
      "Percent of total pct from missing mappings: 3.78%\n"
     ]
    }
   ],
   "source": [
    "task_statements_new_df = pd.read_csv(\"../extra_data/Task Statements 20.1.csv\")\n",
    "task_statements_claude_df = pd.read_csv(\"../original_data/onet_task_statements.csv\")\n",
    "\n",
    "task_statements_new_df[\"task_norm\"] = task_statements_new_df[\"Task\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "task_statements_claude_df[\"task_norm\"] = task_statements_claude_df[\"Task\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "\n",
    "new_tasks_set = set(task_statements_new_df[\"task_norm\"].dropna().unique())\n",
    "claude_tasks_set = set(task_statements_claude_df[\"task_norm\"].dropna().unique())\n",
    "\n",
    "# 1. Intersection (tasks in both)\n",
    "tasks_in_both = new_tasks_set & claude_tasks_set\n",
    "print(f\"Tasks in both: {len(tasks_in_both)}\")\n",
    "\n",
    "# 2. Only in new\n",
    "tasks_only_in_new = new_tasks_set - claude_tasks_set\n",
    "print(f\"Tasks only in new: {len(tasks_only_in_new)}\")\n",
    "\n",
    "# 3. Only in Claude (old)\n",
    "tasks_only_in_claude = claude_tasks_set - new_tasks_set\n",
    "print(f\"Tasks only in Claude's set: {len(tasks_only_in_claude)}\")\n",
    "\n",
    "\n",
    "task_mappings_df = pd.read_csv(\"../original_data/onet_task_mappings.csv\")\n",
    "task_mappings_df[\"task_norm\"] = task_mappings_df[\"task_name\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Unique normalized task sets\n",
    "new_tasks_set = set(task_statements_new_df[\"task_norm\"].dropna().unique())\n",
    "claude_pct_tasks_set = set(task_mappings_df[\"task_norm\"].dropna().unique())\n",
    "\n",
    "# Intersections and gaps\n",
    "in_both = claude_pct_tasks_set & new_tasks_set\n",
    "only_in_claude_pct = claude_pct_tasks_set - new_tasks_set\n",
    "\n",
    "# Prints\n",
    "print(\"Claude % tasks (unique):\", len(claude_pct_tasks_set))\n",
    "print(\"In both (mapped % task exists in NEW):\", len(in_both))\n",
    "print(\"Missing in NEW (mapped % task not found):\", len(only_in_claude_pct))\n",
    "print(\"Coverage (% of Claude % tasks found in NEW):\",\n",
    "      round(100 * len(in_both) / max(1, len(claude_pct_tasks_set)), 2), \"%\")\n",
    "\n",
    "# Optional: list a few missing for spot-check\n",
    "print(\"\\nSample missing tasks:\", list(sorted(only_in_claude_pct))[:20])\n",
    "\n",
    "\n",
    "missing_pct_sum = task_mappings_df[task_mappings_df[\"task_norm\"].isin(only_in_claude_pct)][\"pct\"].sum()\n",
    "\n",
    "# Total pct for all tasks\n",
    "total_pct_sum = task_mappings_df[\"pct\"].sum()\n",
    "\n",
    "# Percent composition of missing tasks\n",
    "missing_pct_percent = 100 * missing_pct_sum / total_pct_sum\n",
    "\n",
    "print(f\"Sum of pct for missing tasks: {missing_pct_sum}\")\n",
    "print(f\"Percent of total pct from missing tasks: {missing_pct_percent:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# Load ratings file\n",
    "task_ratings_df = pd.read_csv(\"../extra_data/Task Ratings 20.1.csv\")\n",
    "\n",
    "# Normalize 'Task' column in ratings\n",
    "task_ratings_df[\"task_norm\"] = task_ratings_df[\"Task\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "\n",
    "ratings_tasks_set = set(task_ratings_df[\"task_norm\"].dropna().unique())\n",
    "\n",
    "print(\"\\n--- Ratings File Checks ---\")\n",
    "\n",
    "# 1. Task Statements vs Ratings\n",
    "statements_in_ratings = new_tasks_set & ratings_tasks_set\n",
    "statements_missing_in_ratings = new_tasks_set - ratings_tasks_set\n",
    "\n",
    "print(f\"Task statements in ratings: {len(statements_in_ratings)} / {len(new_tasks_set)} \"\n",
    "      f\"({100*len(statements_in_ratings)/len(new_tasks_set):.2f}%)\")\n",
    "print(f\"Task statements missing in ratings: {len(statements_missing_in_ratings)}\")\n",
    "print(\"Sample missing from ratings (statements):\", list(sorted(statements_missing_in_ratings))[:10])\n",
    "\n",
    "# 2. Task Mappings vs Ratings\n",
    "mappings_in_ratings = claude_pct_tasks_set & ratings_tasks_set\n",
    "mappings_missing_in_ratings = claude_pct_tasks_set - ratings_tasks_set\n",
    "\n",
    "print(f\"\\nTask mappings in ratings: {len(mappings_in_ratings)} / {len(claude_pct_tasks_set)} \"\n",
    "      f\"({100*len(mappings_in_ratings)/len(claude_pct_tasks_set):.2f}%)\")\n",
    "print(f\"Task mappings missing in ratings: {len(mappings_missing_in_ratings)}\")\n",
    "print(\"Sample missing from ratings (mappings):\", list(sorted(mappings_missing_in_ratings))[:10])\n",
    "\n",
    "# 3. (Optional) % sum of missing mappings\n",
    "missing_mappings_pct_sum = task_mappings_df[task_mappings_df[\"task_norm\"].isin(mappings_missing_in_ratings)][\"pct\"].sum()\n",
    "total_pct_sum = task_mappings_df[\"pct\"].sum()\n",
    "missing_mappings_pct_percent = 100 * missing_mappings_pct_sum / total_pct_sum\n",
    "\n",
    "print(f\"\\nSum of pct for missing mappings: {missing_mappings_pct_sum}\")\n",
    "print(f\"Percent of total pct from missing mappings: {missing_mappings_pct_percent:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f3b6e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>pct</th>\n",
       "      <th>task_norm</th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Incumbents Responding</th>\n",
       "      <th>Date</th>\n",
       "      <th>Domain Source</th>\n",
       "      <th>task_Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>act as advisers to student organizations.</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "      <td>25-1011.00</td>\n",
       "      <td>Business Teachers, Postsecondary</td>\n",
       "      <td>5682.0</td>\n",
       "      <td>Act as advisers to student organizations.</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>104.0</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act as advisers to student organizations.</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "      <td>25-1021.00</td>\n",
       "      <td>Computer Science Teachers, Postsecondary</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>Act as advisers to student organizations.</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>90.0</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>act as advisers to student organizations.</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "      <td>25-1022.00</td>\n",
       "      <td>Mathematical Science Teachers, Postsecondary</td>\n",
       "      <td>5726.0</td>\n",
       "      <td>Act as advisers to student organizations.</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>116.0</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>act as advisers to student organizations.</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "      <td>25-1031.00</td>\n",
       "      <td>Architecture Teachers, Postsecondary</td>\n",
       "      <td>5751.0</td>\n",
       "      <td>Act as advisers to student organizations.</td>\n",
       "      <td>Core</td>\n",
       "      <td>69.0</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>act as advisers to student organizations.</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "      <td>25-1032.00</td>\n",
       "      <td>Engineering Teachers, Postsecondary</td>\n",
       "      <td>5774.0</td>\n",
       "      <td>Act as advisers to student organizations.</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>54.0</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>act as advisers to student organizations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>write, design, or edit web page content, or di...</td>\n",
       "      <td>0.320908</td>\n",
       "      <td>write  design  or edit web page content  or di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>write, present, and publish reports that recor...</td>\n",
       "      <td>0.117393</td>\n",
       "      <td>write  present  and publish reports that recor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>write, review, or execute plans for testing ne...</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>write  review  or execute plans for testing ne...</td>\n",
       "      <td>15-1299.03</td>\n",
       "      <td>Document Management Specialists</td>\n",
       "      <td>16220.0</td>\n",
       "      <td>Write, review, or execute plans for testing ne...</td>\n",
       "      <td>Core</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/2021</td>\n",
       "      <td>Occupational Expert</td>\n",
       "      <td>write  review  or execute plans for testing ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>write, review, or maintain engineering documen...</td>\n",
       "      <td>0.076872</td>\n",
       "      <td>write  review  or maintain engineering documen...</td>\n",
       "      <td>17-2141.02</td>\n",
       "      <td>Automotive Engineers</td>\n",
       "      <td>16425.0</td>\n",
       "      <td>Write, review, or maintain engineering documen...</td>\n",
       "      <td>Core</td>\n",
       "      <td>21.0</td>\n",
       "      <td>08/2022</td>\n",
       "      <td>Occupational Expert</td>\n",
       "      <td>write  review  or maintain engineering documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>write, update, and maintain computer programs ...</td>\n",
       "      <td>1.153861</td>\n",
       "      <td>write  update  and maintain computer programs ...</td>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>Write, update, and maintain computer programs ...</td>\n",
       "      <td>Core</td>\n",
       "      <td>70.0</td>\n",
       "      <td>08/2018</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>write  update  and maintain computer programs ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4216 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              task_name       pct  \\\n",
       "0             act as advisers to student organizations.  0.006775   \n",
       "1             act as advisers to student organizations.  0.006775   \n",
       "2             act as advisers to student organizations.  0.006775   \n",
       "3             act as advisers to student organizations.  0.006775   \n",
       "4             act as advisers to student organizations.  0.006775   \n",
       "...                                                 ...       ...   \n",
       "4211  write, design, or edit web page content, or di...  0.320908   \n",
       "4212  write, present, and publish reports that recor...  0.117393   \n",
       "4213  write, review, or execute plans for testing ne...  0.010944   \n",
       "4214  write, review, or maintain engineering documen...  0.076872   \n",
       "4215  write, update, and maintain computer programs ...  1.153861   \n",
       "\n",
       "                                              task_norm O*NET-SOC Code  \\\n",
       "0              act as advisers to student organizations     25-1011.00   \n",
       "1              act as advisers to student organizations     25-1021.00   \n",
       "2              act as advisers to student organizations     25-1022.00   \n",
       "3              act as advisers to student organizations     25-1031.00   \n",
       "4              act as advisers to student organizations     25-1032.00   \n",
       "...                                                 ...            ...   \n",
       "4211  write  design  or edit web page content  or di...            NaN   \n",
       "4212  write  present  and publish reports that recor...            NaN   \n",
       "4213  write  review  or execute plans for testing ne...     15-1299.03   \n",
       "4214  write  review  or maintain engineering documen...     17-2141.02   \n",
       "4215  write  update  and maintain computer programs ...     15-1251.00   \n",
       "\n",
       "                                             Title  Task ID  \\\n",
       "0                 Business Teachers, Postsecondary   5682.0   \n",
       "1         Computer Science Teachers, Postsecondary   5700.0   \n",
       "2     Mathematical Science Teachers, Postsecondary   5726.0   \n",
       "3             Architecture Teachers, Postsecondary   5751.0   \n",
       "4              Engineering Teachers, Postsecondary   5774.0   \n",
       "...                                            ...      ...   \n",
       "4211                                           NaN      NaN   \n",
       "4212                                           NaN      NaN   \n",
       "4213               Document Management Specialists  16220.0   \n",
       "4214                          Automotive Engineers  16425.0   \n",
       "4215                          Computer Programmers   1270.0   \n",
       "\n",
       "                                                   Task     Task Type  \\\n",
       "0             Act as advisers to student organizations.  Supplemental   \n",
       "1             Act as advisers to student organizations.  Supplemental   \n",
       "2             Act as advisers to student organizations.  Supplemental   \n",
       "3             Act as advisers to student organizations.          Core   \n",
       "4             Act as advisers to student organizations.  Supplemental   \n",
       "...                                                 ...           ...   \n",
       "4211                                                NaN           NaN   \n",
       "4212                                                NaN           NaN   \n",
       "4213  Write, review, or execute plans for testing ne...          Core   \n",
       "4214  Write, review, or maintain engineering documen...          Core   \n",
       "4215  Write, update, and maintain computer programs ...          Core   \n",
       "\n",
       "      Incumbents Responding     Date        Domain Source  \\\n",
       "0                     104.0  08/2019            Incumbent   \n",
       "1                      90.0  08/2019            Incumbent   \n",
       "2                     116.0  08/2019            Incumbent   \n",
       "3                      69.0  08/2019            Incumbent   \n",
       "4                      54.0  08/2019            Incumbent   \n",
       "...                     ...      ...                  ...   \n",
       "4211                    NaN      NaN                  NaN   \n",
       "4212                    NaN      NaN                  NaN   \n",
       "4213                   20.0  08/2021  Occupational Expert   \n",
       "4214                   21.0  08/2022  Occupational Expert   \n",
       "4215                   70.0  08/2018            Incumbent   \n",
       "\n",
       "                                              task_Norm  \n",
       "0              act as advisers to student organizations  \n",
       "1              act as advisers to student organizations  \n",
       "2              act as advisers to student organizations  \n",
       "3              act as advisers to student organizations  \n",
       "4              act as advisers to student organizations  \n",
       "...                                                 ...  \n",
       "4211                                                NaN  \n",
       "4212                                                NaN  \n",
       "4213  write  review  or execute plans for testing ne...  \n",
       "4214  write  review  or maintain engineering documen...  \n",
       "4215  write  update  and maintain computer programs ...  \n",
       "\n",
       "[4216 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_statements_df = pd.read_csv(\"../extra_data/task_statements_new.csv\")\n",
    "task_mappings_df = pd.read_csv(\"../original_data/onet_task_mappings.csv\")\n",
    "\n",
    "task_statements_df[\"task_Norm\"] = task_statements_df[\"Task\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "task_mappings_df[\"task_norm\"] = task_mappings_df[\"task_name\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "merged_test = task_mappings_df.merge(\n",
    "    task_statements_df,\n",
    "    left_on=\"task_norm\",\n",
    "    right_on=\"task_Norm\",\n",
    "    how=\"left\"\n",
    ")\n",
    "merged_test\n",
    "#merged_test.loc[merged_test[\"pct\"].isna(), \"task_Norm\"].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81dac79",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5db9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_statements_df = pd.read_csv(\"../original_data/onet_task_statements.csv\")\n",
    "crosswalk_df = pd.read_csv(\"../extra_data/2010_to_2019_soc_crosswalk.csv\")\n",
    "task_statements_df[\"title_norm\"] = task_statements_df[\"Title\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "crosswalk_df[\"2010_title_norm\"] = crosswalk_df[\"O*NET-SOC 2010 Title\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "crosswalk_df[\"2019_title_norm\"] = crosswalk_df[\"O*NET-SOC 2019 Title\"].str.lower().str.replace(\"[^a-z0-9]\", \" \", regex=True).str.strip()\n",
    "\n",
    "merged = pd.merge(\n",
    "    task_statements_df,\n",
    "    crosswalk_df,\n",
    "    left_on=\"title_norm\",\n",
    "    right_on=\"2010_title_norm\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "merged[\"O*NET-SOC 2019 Title\"].isna().sum()\n",
    "merged.to_csv(\"test_3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b9ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with different titles (normalized): 4768\n",
      "                                                                    Title                                                                               O*NET-SOC 2019 Title\n",
      "                                                              Accountants                                                                           Accountants and Auditors\n",
      "                                         Administrative Services Managers                                                                                Facilities Managers\n",
      "Adult Basic and Secondary Education and Literacy Teachers and Instructors     Adult Basic Education, Adult Secondary Education, and English as a Second Language Instructors\n",
      "                         Aerospace Engineering and Operations Technicians                                 Aerospace Engineering and Operations Technologists and Technicians\n",
      "                                                          Anthropologists                                                                  Anthropologists and Archeologists\n",
      "                                                  Appraisers, Real Estate                                                            Appraisers and Assessors of Real Estate\n",
      "                                                    Aquacultural Managers                                                 Farmers, Ranchers, and Other Agricultural Managers\n",
      "                                                            Archeologists                                                                  Anthropologists and Archeologists\n",
      "                                                   Architectural Drafters                                                                   Architectural and Civil Drafters\n",
      "                                                                Assessors                                                            Appraisers and Assessors of Real Estate\n",
      "                                    Audio and Video Equipment Technicians                                                                        Audio and Video Technicians\n",
      "                      Audio-Visual and Multimedia Collections Specialists                                                       Librarians and Media Collections Specialists\n",
      "                                                                 Auditors                                                                           Accountants and Auditors\n",
      "                                              Automotive Master Mechanics                                                       Automotive Service Technicians and Mechanics\n",
      "                                         Automotive Specialty Technicians                                                       Automotive Service Technicians and Mechanics\n",
      "                                           Billing, Cost, and Rate Clerks                                                                         Billing and Posting Clerks\n",
      "                                                    Biochemical Engineers                                                              Bioengineers and Biomedical Engineers\n",
      "                                                     Biomedical Engineers                                                              Bioengineers and Biomedical Engineers\n",
      "                                                  Broadcast News Analysts                                                          News Analysts, Reporters, and Journalists\n",
      "                                    Bus Drivers, School or Special Client                                                                                Bus Drivers, School\n",
      "                                    Bus Drivers, School or Special Client                                                                     Shuttle Drivers and Chauffeurs\n",
      "                  Camera Operators, Television, Video, and Motion Picture                                                      Camera Operators, Television, Video, and Film\n",
      "                                         City and Regional Planning Aides                                                                        Urban and Regional Planners\n",
      "                                                           Civil Drafters                                                                   Architectural and Civil Drafters\n",
      "                                            Civil Engineering Technicians                                                    Civil Engineering Technologists and Technicians\n",
      "                                                                      ...                                                                                                ...\n",
      "                                                    Solderers and Brazers                                                           Welders, Cutters, Solderers, and Brazers\n",
      "           Special Education Teachers, Kindergarten and Elementary School                                                      Special Education Teachers, Elementary School\n",
      "           Special Education Teachers, Kindergarten and Elementary School                                                           Special Education Teachers, Kindergarten\n",
      "                                                         Statement Clerks                                                                         Billing and Posting Clerks\n",
      "                                                Stock Clerks, Sales Floor                                                                         Stockers and Order Fillers\n",
      "                      Stock Clerks- Stockroom, Warehouse, or Storage Yard                                                                         Stockers and Order Fillers\n",
      "                                        Storage and Distribution Managers                                                 Transportation, Storage, and Distribution Managers\n",
      "                                                                 Surgeons                                                              Orthopedic Surgeons, Except Pediatric\n",
      "                                                                 Surgeons                                                                                 Pediatric Surgeons\n",
      "                                                                 Surgeons                                                                                Surgeons, All Other\n",
      "                                                    Surveying Technicians                                                                  Surveying and Mapping Technicians\n",
      "                                              Taxi Drivers and Chauffeurs                                                                     Shuttle Drivers and Chauffeurs\n",
      "                                              Taxi Drivers and Chauffeurs                                                                                       Taxi Drivers\n",
      "                                                       Teacher Assistants                                                                     Teaching Assistants, All Other\n",
      "                                                       Teacher Assistants Teaching Assistants, Preschool, Elementary, Middle, and Secondary School, Except Special Education\n",
      "                                                       Teacher Assistants                                                             Teaching Assistants, Special Education\n",
      "                                             Technical Directors/Managers                                                                 Media Technical Directors/Managers\n",
      "                                                  Tile and Marble Setters                                                                             Tile and Stone Setters\n",
      "                      Transportation Attendants, Except Flight Attendants                                                                               Passenger Attendants\n",
      "                                                  Transportation Managers                                                 Transportation, Storage, and Distribution Managers\n",
      "                             Vocational Education Teachers, Postsecondary                                                 Career/Technical Education Teachers, Postsecondary\n",
      "                                                          Watch Repairers                                                                          Watch and Clock Repairers\n",
      "                                                           Web Developers                                                                Web and Digital Interface Designers\n",
      "                                     Welders, Cutters, and Welder Fitters                                                           Welders, Cutters, Solderers, and Brazers\n",
      "                                             Wind Energy Project Managers                                                                   Wind Energy Development Managers\n"
     ]
    }
   ],
   "source": [
    "def norm(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.fillna(\"\")\n",
    "         .str.lower()\n",
    "         .str.replace(\"[^a-z0-9]\", \" \", regex=True)\n",
    "         .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "         .str.strip()\n",
    "    )\n",
    "\n",
    "# normalized versions\n",
    "t0 = norm(merged[\"Title\"])\n",
    "t19 = norm(merged[\"O*NET-SOC 2019 Title\"])\n",
    "\n",
    "# boolean mask of mismatches\n",
    "diff = t0 != t19\n",
    "\n",
    "print(\"Rows with different titles (normalized):\", diff.sum())\n",
    "\n",
    "# show unique pairs that differ\n",
    "pairs = (merged.loc[diff, [\"Title\", \"O*NET-SOC 2019 Title\"]]\n",
    "         .drop_duplicates()\n",
    "         .sort_values([\"Title\", \"O*NET-SOC 2019 Title\"]))\n",
    "print(pairs.to_string(index=False, max_rows=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "522105bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Initial ONET Data\n",
    "\n",
    "def create_onet_soc_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This takes the onet task statements and merges them with the SOC structure in order to get the SOC major group titles mapped to the tasks.\n",
    "        It then renames columns for better data usage.\n",
    "        It then normalizes the task names by making them all lowercase and stripping whitespace. \n",
    "        It then creates a new column to count the number of occurrences of each task in an occupation, and in an SOC title.\n",
    "        This originally did not rename columns or create a column for n_occurances_soc.\n",
    "    \n",
    "    Args:\n",
    "        onet_path (str): Path to the O*NET task statements CSV file\n",
    "        soc_path (str): Path to the SOC structure CSV file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame containing O*NET data with SOC major group titles\n",
    "    \"\"\"\n",
    "\n",
    "    # Read and process O*NET data\n",
    "    onet_df = pd.read_csv(\"../original_data/onet_task_statements.csv\")\n",
    "    onet_df[\"soc_group_code\"] = onet_df[\"O*NET-SOC Code\"].str[:2]\n",
    "    \n",
    "    # Read and process SOC data\n",
    "    soc_df = pd.read_csv(\"../original_data/SOC_Structure.csv\")\n",
    "    soc_df = soc_df.dropna(subset=['Major Group'])\n",
    "    soc_df[\"soc_group_code\"] = soc_df[\"Major Group\"].str[:2]\n",
    "    \n",
    "    # Merge datasets\n",
    "    task_soc_df = onet_df.merge(\n",
    "        soc_df[['soc_group_code', 'SOC or O*NET-SOC 2019 Title']],\n",
    "        on='soc_group_code',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Rename columns for better usability\n",
    "    task_soc_df.rename(columns={\n",
    "    \"O*NET-SOC Code\": \"occ_group_code\",\n",
    "    \"Title\": \"title\",\n",
    "    \"Task ID\": \"task_id\",\n",
    "    \"Task\": \"task\",\n",
    "    \"Task Type\": \"task_type\",\n",
    "    \"Incumbents Responding\": \"n_responding\",\n",
    "    \"Date\": \"date\",\n",
    "    \"Domain Source\": \"domain_source\",\n",
    "    \"SOC or O*NET-SOC 2019 Title\": \"soc_title\",\n",
    "    }, inplace=True)\n",
    "\n",
    "    task_soc_df[\"task_normalized\"] = task_soc_df[\"task\"].str.lower().str.strip()\n",
    "    task_soc_df[\"n_occurrences\"] = task_soc_df.groupby(\"task_normalized\")[\"title\"].transform(\"nunique\")\n",
    "    task_soc_df[\"n_occurrences_soc\"] = task_soc_df.groupby(\"task_normalized\")[\"soc_title\"].transform(\"nunique\")\n",
    "\n",
    "    return task_soc_df\n",
    "\n",
    "task_soc_df = create_onet_soc_data()\n",
    "#display(task_soc_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09c1e918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>pct</th>\n",
       "      <th>occ_group_code</th>\n",
       "      <th>title</th>\n",
       "      <th>task_id</th>\n",
       "      <th>task</th>\n",
       "      <th>task_type</th>\n",
       "      <th>n_responding</th>\n",
       "      <th>date</th>\n",
       "      <th>domain_source</th>\n",
       "      <th>soc_group_code</th>\n",
       "      <th>soc_title</th>\n",
       "      <th>task_normalized</th>\n",
       "      <th>n_occurrences</th>\n",
       "      <th>n_occurrences_soc</th>\n",
       "      <th>pct_occ_weighted</th>\n",
       "      <th>pct_occ_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direct or conduct studies or research on issue...</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8848.0</td>\n",
       "      <td>Direct or conduct studies or research on issue...</td>\n",
       "      <td>Core</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>direct or conduct studies or research on issue...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>direct, plan, or implement policies, objective...</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8826.0</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>Core</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>direct, plan, or implement policies, objective...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.005237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interpret and explain policies, rules, regulat...</td>\n",
       "      <td>0.049250</td>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8843.0</td>\n",
       "      <td>Interpret and explain policies, rules, regulat...</td>\n",
       "      <td>Core</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>interpret and explain policies, rules, regulat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040504</td>\n",
       "      <td>0.049488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deliver speeches, write articles, or present i...</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8839.0</td>\n",
       "      <td>Deliver speeches, write articles, or present i...</td>\n",
       "      <td>Core</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>deliver speeches, write articles, or present i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.008117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>serve as liaisons between organizations, share...</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8840.0</td>\n",
       "      <td>Serve as liaisons between organizations, share...</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>11</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>serve as liaisons between organizations, share...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.003797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>stop gathering arms when cars are full.</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>53-7033.00</td>\n",
       "      <td>Loading Machine Operators, Underground Mining</td>\n",
       "      <td>15190.0</td>\n",
       "      <td>Stop gathering arms when cars are full.</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>78.0</td>\n",
       "      <td>06/2008</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>53</td>\n",
       "      <td>Transportation and Material Moving Occupations</td>\n",
       "      <td>stop gathering arms when cars are full.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.003404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>collect and test samples of cleaning solutions...</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>53-7061.00</td>\n",
       "      <td>Cleaners of Vehicles and Equipment</td>\n",
       "      <td>5010.0</td>\n",
       "      <td>Collect and test samples of cleaning solutions...</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/2013</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>53</td>\n",
       "      <td>Transportation and Material Moving Occupations</td>\n",
       "      <td>collect and test samples of cleaning solutions...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>stack cargo in locations such as transit sheds...</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>53-7062.00</td>\n",
       "      <td>Laborers and Freight, Stock, and Material Move...</td>\n",
       "      <td>10795.0</td>\n",
       "      <td>Stack cargo in locations such as transit sheds...</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/2013</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>53</td>\n",
       "      <td>Transportation and Material Moving Occupations</td>\n",
       "      <td>stack cargo in locations such as transit sheds...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.002880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4243</th>\n",
       "      <td>test materials and solutions, using testing eq...</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>53-7072.00</td>\n",
       "      <td>Pump Operators, Except Wellhead Pumpers</td>\n",
       "      <td>14622.0</td>\n",
       "      <td>Test materials and solutions, using testing eq...</td>\n",
       "      <td>Supplemental</td>\n",
       "      <td>105.0</td>\n",
       "      <td>06/2007</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>53</td>\n",
       "      <td>Transportation and Material Moving Occupations</td>\n",
       "      <td>test materials and solutions, using testing eq...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.001964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>none</td>\n",
       "      <td>0.481557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.396040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4245 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              task_name       pct  \\\n",
       "0     direct or conduct studies or research on issue...  0.004951   \n",
       "1     direct, plan, or implement policies, objective...  0.005212   \n",
       "2     interpret and explain policies, rules, regulat...  0.049250   \n",
       "3     deliver speeches, write articles, or present i...  0.008078   \n",
       "4     serve as liaisons between organizations, share...  0.003778   \n",
       "...                                                 ...       ...   \n",
       "4240            stop gathering arms when cars are full.  0.003388   \n",
       "4241  collect and test samples of cleaning solutions...  0.002476   \n",
       "4242  stack cargo in locations such as transit sheds...  0.002866   \n",
       "4243  test materials and solutions, using testing eq...  0.001954   \n",
       "4244                                               none  0.481557   \n",
       "\n",
       "     occ_group_code                                              title  \\\n",
       "0        11-1011.00                                   Chief Executives   \n",
       "1        11-1011.00                                   Chief Executives   \n",
       "2        11-1011.00                                   Chief Executives   \n",
       "3        11-1011.00                                   Chief Executives   \n",
       "4        11-1011.00                                   Chief Executives   \n",
       "...             ...                                                ...   \n",
       "4240     53-7033.00      Loading Machine Operators, Underground Mining   \n",
       "4241     53-7061.00                 Cleaners of Vehicles and Equipment   \n",
       "4242     53-7062.00  Laborers and Freight, Stock, and Material Move...   \n",
       "4243     53-7072.00            Pump Operators, Except Wellhead Pumpers   \n",
       "4244            NaN                                                NaN   \n",
       "\n",
       "      task_id                                               task  \\\n",
       "0      8848.0  Direct or conduct studies or research on issue...   \n",
       "1      8826.0  Direct, plan, or implement policies, objective...   \n",
       "2      8843.0  Interpret and explain policies, rules, regulat...   \n",
       "3      8839.0  Deliver speeches, write articles, or present i...   \n",
       "4      8840.0  Serve as liaisons between organizations, share...   \n",
       "...       ...                                                ...   \n",
       "4240  15190.0            Stop gathering arms when cars are full.   \n",
       "4241   5010.0  Collect and test samples of cleaning solutions...   \n",
       "4242  10795.0  Stack cargo in locations such as transit sheds...   \n",
       "4243  14622.0  Test materials and solutions, using testing eq...   \n",
       "4244      NaN                                                NaN   \n",
       "\n",
       "         task_type  n_responding     date domain_source soc_group_code  \\\n",
       "0             Core          87.0  07/2014     Incumbent             11   \n",
       "1             Core          87.0  07/2014     Incumbent             11   \n",
       "2             Core          87.0  07/2014     Incumbent             11   \n",
       "3             Core          87.0  07/2014     Incumbent             11   \n",
       "4     Supplemental          87.0  07/2014     Incumbent             11   \n",
       "...            ...           ...      ...           ...            ...   \n",
       "4240  Supplemental          78.0  06/2008     Incumbent             53   \n",
       "4241  Supplemental          87.0  07/2013     Incumbent             53   \n",
       "4242  Supplemental          87.0  07/2013     Incumbent             53   \n",
       "4243  Supplemental         105.0  06/2007     Incumbent             53   \n",
       "4244           NaN           NaN      NaN           NaN            NaN   \n",
       "\n",
       "                                           soc_title  \\\n",
       "0                             Management Occupations   \n",
       "1                             Management Occupations   \n",
       "2                             Management Occupations   \n",
       "3                             Management Occupations   \n",
       "4                             Management Occupations   \n",
       "...                                              ...   \n",
       "4240  Transportation and Material Moving Occupations   \n",
       "4241  Transportation and Material Moving Occupations   \n",
       "4242  Transportation and Material Moving Occupations   \n",
       "4243  Transportation and Material Moving Occupations   \n",
       "4244                                             NaN   \n",
       "\n",
       "                                        task_normalized  n_occurrences  \\\n",
       "0     direct or conduct studies or research on issue...            1.0   \n",
       "1     direct, plan, or implement policies, objective...            1.0   \n",
       "2     interpret and explain policies, rules, regulat...            1.0   \n",
       "3     deliver speeches, write articles, or present i...            1.0   \n",
       "4     serve as liaisons between organizations, share...            1.0   \n",
       "...                                                 ...            ...   \n",
       "4240            stop gathering arms when cars are full.            1.0   \n",
       "4241  collect and test samples of cleaning solutions...            1.0   \n",
       "4242  stack cargo in locations such as transit sheds...            1.0   \n",
       "4243  test materials and solutions, using testing eq...            1.0   \n",
       "4244                                                NaN            NaN   \n",
       "\n",
       "      n_occurrences_soc  pct_occ_weighted  pct_occ_norm  \n",
       "0                   1.0          0.004072      0.004975  \n",
       "1                   1.0          0.004286      0.005237  \n",
       "2                   1.0          0.040504      0.049488  \n",
       "3                   1.0          0.006644      0.008117  \n",
       "4                   1.0          0.003107      0.003797  \n",
       "...                 ...               ...           ...  \n",
       "4240                1.0          0.002786      0.003404  \n",
       "4241                1.0          0.002036      0.002488  \n",
       "4242                1.0          0.002357      0.002880  \n",
       "4243                1.0          0.001607      0.001964  \n",
       "4244                NaN          0.396040           NaN  \n",
       "\n",
       "[4245 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add Claude data\n",
    "def add_claude_pct(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This loads in the tasks and percentage of occurrences from the Claude data, and merges it with the tasks in our data set we already have. \n",
    "        It then normalizes the percentages of occurances of tasks and has one column for weighted percents based multiple occurrences, and one where that weight is normalized\n",
    "        It then sorts it based on the O*NET-SOC Code.\n",
    "        This originally did not create a column for the weighted percentage of occurrences.\n",
    "    \n",
    "    Args:\n",
    "        task_soc_df (pd.DataFrame): DataFrame containing O*NET tasks and SOC titles.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with percentage of occurrences added.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load task mappings from Claude data\n",
    "    task_mappings_df = pd.read_csv(\"../original_data/onet_task_mappings.csv\")\n",
    "    \n",
    "    # Merge with existing task DataFrame\n",
    "    merged = task_mappings_df.merge(\n",
    "        df,\n",
    "        left_on=\"task_name\",\n",
    "        right_on=\"task_normalized\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Calculate weighted and normalized percentages\n",
    "    merged[\"pct_occ_weighted\"] = 100 * merged[\"pct\"] / merged[\"pct\"].sum()\n",
    "    merged[\"pct_occ_norm\"] = 100 * (merged[\"pct\"] / merged[\"n_occurrences\"]) / (merged[\"pct\"] / merged[\"n_occurrences\"]).sum()\n",
    "    \n",
    "    # Sort by O*NET-SOC Code\n",
    "    merged.sort_values(by=\"occ_group_code\", ascending=True, inplace=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "task_soc_pct_all = add_claude_pct(task_soc_df)\n",
    "display(task_soc_pct_all.reset_index(drop=True))\n",
    "task_soc_pct_all.to_csv(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c465f",
   "metadata": {},
   "source": [
    "### Extra Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2940280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_emp missing: 448\n",
      "['Funeral Service Managers' 'Buyers and Purchasing Agents, Farm Products'\n",
      " 'Wholesale and Retail Buyers, Except Farm Products'\n",
      " 'Purchasing Agents, Except Wholesale, Retail, and Farm Products'\n",
      " 'Assessors' 'Appraisers, Real Estate' 'Informatics Nurse Specialists'\n",
      " 'Software Developers, Applications'\n",
      " 'Software Developers, Systems Software'\n",
      " 'Telecommunications Engineering Specialists'\n",
      " 'Software Quality Assurance Engineers and Testers'\n",
      " 'Computer Systems Engineers/Architects' 'Web Administrators'\n",
      " 'Geospatial Information Scientists and Technologists'\n",
      " 'Geographic Information Systems Technicians'\n",
      " 'Data Warehousing Specialists' 'Business Intelligence Analysts'\n",
      " 'Information Technology Project Managers' 'Search Marketing Strategists'\n",
      " 'Video Game Designers' 'Document Management Specialists'\n",
      " 'Mathematical Technicians' 'Clinical Psychologists'\n",
      " 'Counseling Psychologists' 'Geophysical Data Technicians'\n",
      " 'Geological Sample Test Technicians'\n",
      " 'Substance Abuse and Behavioral Disorder Counselors'\n",
      " 'Mental Health Counselors' 'Court Reporters'\n",
      " 'Graduate Teaching Assistants' 'Librarians'\n",
      " 'Audio-Visual and Multimedia Collections Specialists'\n",
      " 'Teacher Assistants' 'Public Address System and Other Announcers'\n",
      " 'Broadcast News Analysts' 'Reporters and Correspondents'\n",
      " 'Radio Operators' 'Family and General Practitioners'\n",
      " 'Internists, General' 'Allergists and Immunologists' 'Hospitalists'\n",
      " 'Nuclear Medicine Physicians' 'Ophthalmologists' 'Pathologists'\n",
      " 'Physical Medicine and Rehabilitation Physicians'\n",
      " 'Preventive Medicine Physicians' 'Sports Medicine Physicians'\n",
      " 'Naturopathic Physicians' 'Orthoptists'\n",
      " 'Medical and Clinical Laboratory Technologists'\n",
      " 'Cytogenetic Technologists' 'Cytotechnologists'\n",
      " 'Histotechnologists and Histologic Technicians'\n",
      " 'Medical and Clinical Laboratory Technicians'\n",
      " 'Medical Records and Health Information Technicians' 'Home Health Aides'\n",
      " 'Combined Food Preparation and Serving Workers, Including Fast Food'\n",
      " 'Counter Attendants, Cafeteria, Food Concession, and Coffee Shop'\n",
      " 'Baristas' 'Gaming Supervisors' 'Spa Managers' 'Tour Guides and Escorts'\n",
      " 'Travel Guides' 'Personal Care Aides' 'Energy Brokers'\n",
      " 'Stock Clerks, Sales Floor'\n",
      " 'Stock Clerks- Stockroom, Warehouse, or Storage Yard'\n",
      " 'Computer Operators' 'Weatherization Installers and Technicians'\n",
      " 'Electrical and Electronic Equipment Assemblers'\n",
      " 'Electromechanical Equipment Assemblers'\n",
      " 'Computer-Controlled Machine Tool Operators, Metal and Plastic'\n",
      " 'Computer Numerically Controlled Machine Tool Programmers, Metal and Plastic'\n",
      " 'First-Line Supervisors of Helpers, Laborers, and Material Movers, Hand'\n",
      " 'Recycling Coordinators'\n",
      " 'First-Line Supervisors of Transportation and Material-Moving Machine and Vehicle Operators'\n",
      " 'Bus Drivers, School or Special Client' 'Taxi Drivers and Chauffeurs'\n",
      " 'Railroad Brake, Signal, and Switch Operators'\n",
      " 'Excavating and Loading Machine and Dragline Operators'\n",
      " 'Loading Machine Operators, Underground Mining' nan]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_emp_wage_data(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This loads in the employment wage data  and merges it into the given dataframe with the desired columns on the occupation code.\n",
    "        If a row doesn't match, we will fall back to merging on occupation title. \n",
    "        All column names in the resulting DataFrame will be lowercase.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input the df with the ONET and Claude data merged.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame with employment and wage data\n",
    "    \"\"\"\n",
    "    emp_wage_df = pd.read_csv(\"../extra_data/emp_wage_national.csv\")\n",
    "\n",
    "    # Standardize for merges\n",
    "    df[\"occ_group_code\"] = df[\"occ_group_code\"].str[:7]\n",
    "    df[\"title_normalized\"] = df[\"title\"].str.lower().str.strip()\n",
    "    emp_wage_df[\"occ_title_normalized\"] = emp_wage_df[\"OCC_TITLE\"].str.lower().str.strip()\n",
    "\n",
    "    wage_cols = [\n",
    "            \"OCC_CODE\", \"AREA_TITLE\", \"TOT_EMP\", \"EMP_PRSE\", \"JOBS_1000\",\n",
    "            \"LOC_QUOTIENT\", \"PCT_TOTAL\", \"PCT_RPT\", \"H_MEAN\", \"A_MEAN\",\n",
    "            \"MEAN_PRSE\", \"H_PCT10\", \"H_PCT25\", \"H_MEDIAN\", \"H_PCT75\", \"H_PCT90\",\n",
    "            \"A_PCT10\", \"A_PCT25\", \"A_MEDIAN\", \"A_PCT75\", \"A_PCT90\", \"ANNUAL\", \"HOURLY\", \"occ_title_normalized\"\n",
    "        ]\n",
    "\n",
    "    # Perform merge\n",
    "    merged_df = pd.merge(\n",
    "        df,\n",
    "        emp_wage_df[wage_cols],\n",
    "        left_on=\"occ_group_code\",\n",
    "        right_on=\"OCC_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    merged_matched = merged_df[merged_df[\"TOT_EMP\"].notna()]\n",
    "    unmatched = merged_df[merged_df[\"TOT_EMP\"].isna()]\n",
    "    unmatched = unmatched.drop(columns=wage_cols, errors=\"ignore\")\n",
    "\n",
    "    merged_unmatched = pd.merge(\n",
    "        unmatched,\n",
    "        emp_wage_df[wage_cols],\n",
    "        left_on=\"title_normalized\",\n",
    "        right_on=\"occ_title_normalized\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    final_merged = pd.concat([merged_matched, merged_unmatched], ignore_index=True)\n",
    "    final_merged.drop(columns=[\"title_normalized\", \"occ_title_normalized\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "\n",
    "    # Convert all column names to lowercase\n",
    "    final_merged.columns = [col.lower() for col in final_merged.columns]\n",
    "\n",
    "    return final_merged\n",
    "\n",
    "task_emp_wage_df = add_emp_wage_data(task_soc_pct_all)\n",
    "#display(task_emp_wage_df)\n",
    "print(\"tot_emp missing:\", task_emp_wage_df[\"tot_emp\"].isna().sum())\n",
    "print(task_emp_wage_df.loc[task_emp_wage_df[\"tot_emp\"].isna(), \"title\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db9ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task ratings processing\n",
    "\n",
    "def add_task_ratings():\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This function reads the task ratings from an Excel file, processes it to extract frequency, importance, and relevance ratings,\n",
    "        and merges them into a single DataFrame with the desired structure.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input the df with the ONET, Claude, and emp and wage data merged.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame with task ratings including frequency, importance, and relevance.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    task_ratings_df = pd.read_csv(\"../extra_data/task_ratings.csv\")\n",
    "\n",
    "\n",
    "# Frequency mapping. Assuming a 52 week year with 5 working days per week, these are corresponding survey questions::\n",
    "# 1 Once per year or less (Assuming 1 time per year)\n",
    "# 2 More than once per year (Assuming 3 times per year)\n",
    "# 3 More than once per month (Assuming 48 times per year, 3 times per month)\n",
    "# 4 More than once per week (Assuming 130 times per year, 2.5 times per week)\n",
    "# 5 Daily\n",
    "# 6 Several times per day (Assuming 3 times per day)\n",
    "# 7 Hourly or more often (Assuming 12 times per day, 1.5 times per hour)\n",
    "    frequency_weights = {\n",
    "        1: 1 / 260,\n",
    "        2: 3 / 260,\n",
    "        3: 48 / 260,\n",
    "        4: 130 / 260,\n",
    "        5: 1,\n",
    "        6: 3,\n",
    "        7: 12\n",
    "    }\n",
    "\n",
    "\n",
    "    # Get freq rows, drop unusable ones, generate freq aggregates\n",
    "    freq_df = task_ratings_df[task_ratings_df[\"Scale ID\"] == \"FT\"].copy()\n",
    "\n",
    "    # Drop rows without category or invalid categories\n",
    "    freq_df = freq_df[pd.to_numeric(freq_df[\"Category\"], errors='coerce').notnull()]\n",
    "    freq_df[\"Category\"] = freq_df[\"Category\"].astype(int)\n",
    "\n",
    "    # Apply weights\n",
    "    freq_df[\"freq_mean\"] = freq_df[\"Data Value\"] * freq_df[\"Category\"].map(frequency_weights) / 100\n",
    "    freq_df[\"freq_lower\"] = freq_df[\"Lower CI Bound\"] * freq_df[\"Category\"].map(frequency_weights) / 100\n",
    "    freq_df[\"freq_upper\"] = freq_df[\"Upper CI Bound\"] * freq_df[\"Category\"].map(frequency_weights) / 100\n",
    "\n",
    "    # Sum across categories to get per-task total\n",
    "    freq_agg = freq_df.groupby([\"O*NET-SOC Code\", \"Title\", \"Task ID\", \"Task\"]).agg({\n",
    "        \"freq_mean\": \"sum\",\n",
    "        \"freq_lower\": \"sum\",\n",
    "        \"freq_upper\": \"sum\"\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    # Get importance and relevance ratings\n",
    "    importance_df = task_ratings_df[task_ratings_df[\"Scale ID\"] == \"IM\"].copy()\n",
    "    importance_df = importance_df[[\"O*NET-SOC Code\", \"Title\", \"Task ID\", \"Task\", \n",
    "                                \"Data Value\", \"Lower CI Bound\", \"Upper CI Bound\"]]\n",
    "    importance_df = importance_df.rename(columns={\n",
    "        \"Data Value\": \"importance\",\n",
    "        \"Lower CI Bound\": \"importance_lower\",\n",
    "        \"Upper CI Bound\": \"importance_upper\"\n",
    "    })\n",
    "\n",
    "    relevance_df = task_ratings_df[task_ratings_df[\"Scale ID\"] == \"RT\"].copy()\n",
    "    relevance_df = relevance_df[[\"O*NET-SOC Code\", \"Title\", \"Task ID\", \"Task\", \n",
    "                                \"Data Value\", \"Lower CI Bound\", \"Upper CI Bound\"]]\n",
    "    relevance_df = relevance_df.rename(columns={\n",
    "        \"Data Value\": \"relevance\",\n",
    "        \"Lower CI Bound\": \"relevance_lower\",\n",
    "        \"Upper CI Bound\": \"relevance_upper\"\n",
    "    })\n",
    "\n",
    "\n",
    "    # Merge ratings\n",
    "    merged_ratings = freq_agg.merge(importance_df, on=[\"O*NET-SOC Code\", \"Title\", \"Task ID\", \"Task\"], how=\"left\")\n",
    "    merged_ratings = merged_ratings.merge(relevance_df, on=[\"O*NET-SOC Code\", \"Title\", \"Task ID\", \"Task\"], how=\"left\")\n",
    "\n",
    "\n",
    "    merged_ratings[\"task_normalized\"] = merged_ratings[\"Task\"].str.lower().str.strip()\n",
    "\n",
    "\n",
    "    return merged_ratings\n",
    "\n",
    "ratings_df = add_task_ratings()\n",
    "#display(ratings_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "669e5157",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 119\u001b[39m\n\u001b[32m    115\u001b[39m     merged = merged[cols]\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m merged\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m task_final = \u001b[43mmerge_all_and_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_emp_wage_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m task_final.to_csv(\u001b[33m\"\u001b[39m\u001b[33m../new_data/tasks_final.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m#display(task_final.reset_index(drop=True))\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mmerge_all_and_cleanup\u001b[39m\u001b[34m(df, ratings_df)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mDescription:\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    This function merges the task data with the ratings data and performs final cleanup.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \u001b[33;03m    pd.DataFrame: Final merged DataFrame with all necessary information.\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Normalize task names\u001b[39;00m\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Apply batch lemmatization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtask_normalized\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mbatch_lemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m ratings_df[\u001b[33m\"\u001b[39m\u001b[33mtask_normalized\u001b[39m\u001b[33m\"\u001b[39m] = batch_lemmatize(ratings_df[\u001b[33m\"\u001b[39m\u001b[33mTask\u001b[39m\u001b[33m\"\u001b[39m].tolist())\n\u001b[32m     48\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtitle_normalized\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m].str.lower().str.strip()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mbatch_lemmatize\u001b[39m\u001b[34m(texts)\u001b[39m\n\u001b[32m     14\u001b[39m cleaned = []\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mner\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlemmas\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlemma_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_punct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_space\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlemmas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teddy\\Downloads\\OAIPR\\Technical\\aei_data_analysis\\venv\\Lib\\site-packages\\spacy\\language.py:1622\u001b[39m, in \u001b[36mLanguage.pipe\u001b[39m\u001b[34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[39m\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[32m   1621\u001b[39m         docs = pipe(docs)\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teddy\\Downloads\\OAIPR\\Technical\\aei_data_analysis\\venv\\Lib\\site-packages\\spacy\\util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pipe\u001b[39m(\n\u001b[32m   1705\u001b[39m     docs: Iterable[\u001b[33m\"\u001b[39m\u001b[33mDoc\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1706\u001b[39m     proc: \u001b[33m\"\u001b[39m\u001b[33mPipeCallable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1711\u001b[39m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m   1712\u001b[39m ) -> Iterator[\u001b[33m\"\u001b[39m\u001b[33mDoc\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1713\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[32m   1717\u001b[39m         kwargs = \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teddy\\Downloads\\OAIPR\\Technical\\aei_data_analysis\\venv\\Lib\\site-packages\\spacy\\pipeline\\pipe.pyx:48\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teddy\\Downloads\\OAIPR\\Technical\\aei_data_analysis\\venv\\Lib\\site-packages\\spacy\\util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pipe\u001b[39m(\n\u001b[32m   1705\u001b[39m     docs: Iterable[\u001b[33m\"\u001b[39m\u001b[33mDoc\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1706\u001b[39m     proc: \u001b[33m\"\u001b[39m\u001b[33mPipeCallable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1711\u001b[39m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m   1712\u001b[39m ) -> Iterator[\u001b[33m\"\u001b[39m\u001b[33mDoc\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1713\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[32m   1717\u001b[39m         kwargs = \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teddy\\Downloads\\OAIPR\\Technical\\aei_data_analysis\\venv\\Lib\\site-packages\\spacy\\pipeline\\pipe.pyx:50\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teddy\\Downloads\\OAIPR\\Technical\\aei_data_analysis\\venv\\Lib\\site-packages\\spacy\\pipeline\\attributeruler.py:130\u001b[39m, in \u001b[36mAttributeRuler.__call__\u001b[39m\u001b[34m(self, doc)\u001b[39m\n\u001b[32m    128\u001b[39m error_handler = \u001b[38;5;28mself\u001b[39m.get_error_handler()\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     matches = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_annotations(doc, matches)\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teddy\\Downloads\\OAIPR\\Technical\\aei_data_analysis\\venv\\Lib\\site-packages\\spacy\\pipeline\\attributeruler.py:140\u001b[39m, in \u001b[36mAttributeRuler.match\u001b[39m\u001b[34m(self, doc)\u001b[39m\n\u001b[32m    137\u001b[39m matches = \u001b[38;5;28mself\u001b[39m.matcher(doc, allow_missing=\u001b[38;5;28;01mTrue\u001b[39;00m, as_spans=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Sort by the attribute ID, so that later rules have precedence\u001b[39;00m\n\u001b[32m    139\u001b[39m matches = [\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     (\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, m_id, s, e) \u001b[38;5;28;01mfor\u001b[39;00m m_id, s, e \u001b[38;5;129;01min\u001b[39;00m matches  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    141\u001b[39m ]\n\u001b[32m    142\u001b[39m matches.sort()\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m matches\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#Merge all and final cleanup\n",
    "\n",
    "def batch_lemmatize(texts):\n",
    "    \"\"\"\n",
    "    Efficiently lemmatize a list of strings using spaCy's nlp.pipe().\n",
    "    Skips punctuation, whitespace, and possessives.\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "    \n",
    "    # Handle empty/null strings\n",
    "    processed_texts = [str(text).strip() if text and str(text).strip() else \" \" for text in texts]\n",
    "    \n",
    "    cleaned = []\n",
    "    try:\n",
    "        for doc in nlp.pipe(processed_texts, batch_size=1000, disable=[\"ner\", \"parser\"]):\n",
    "            lemmas = [\n",
    "                token.lemma_ for token in doc\n",
    "                if not token.is_punct and not token.is_space and token.text != \"'s\"\n",
    "            ]\n",
    "            result = \" \".join(lemmas).strip()\n",
    "            cleaned.append(result if result else \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch_lemmatize: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def merge_all_and_cleanup(df, ratings_df):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This function merges the task data with the ratings data and performs final cleanup.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing task data.\n",
    "        ratings_df (pd.DataFrame): DataFrame containing task ratings.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Final merged DataFrame with all necessary information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize task names\n",
    "\n",
    "    # Apply batch lemmatization\n",
    "    df[\"task_normalized\"] = batch_lemmatize(df[\"task\"].tolist())\n",
    "    ratings_df[\"task_normalized\"] = batch_lemmatize(ratings_df[\"Task\"].tolist())\n",
    "\n",
    "    df[\"title_normalized\"] = df[\"title\"].str.lower().str.strip()\n",
    "    ratings_df[\"title_normalized\"] = ratings_df[\"Title\"].str.lower().str.strip()\n",
    "\n",
    "    # Count how many times each normalized task appears\n",
    "    task_counts = df[\"task_normalized\"].value_counts()\n",
    "\n",
    "    # Boolean mask for duplicate vs. unique tasks\n",
    "    is_duplicate = df[\"task_normalized\"].isin(task_counts[task_counts > 1].index)\n",
    "    is_unique = ~is_duplicate\n",
    "\n",
    "    # Split the dataframe\n",
    "    df_duplicate_tasks = df[is_duplicate].copy()\n",
    "    df_unique_tasks = df[is_unique].copy()\n",
    "\n",
    "    # Count how many times each normalized task appears\n",
    "    task_counts_ratings = ratings_df[\"task_normalized\"].value_counts()\n",
    "\n",
    "    # Boolean mask for duplicate vs. unique tasks\n",
    "    is_duplicate_ratings = ratings_df[\"task_normalized\"].isin(task_counts_ratings[task_counts_ratings > 1].index)\n",
    "    is_unique_ratings = ~is_duplicate_ratings\n",
    "\n",
    "    # Split the dataframe\n",
    "    df_duplicate_tasks_ratings = ratings_df[is_duplicate_ratings].copy()\n",
    "    df_unique_tasks_ratings = ratings_df[is_unique_ratings].copy()\n",
    "\n",
    "    # Merge on unique tasks\n",
    "    merged_unique = df_unique_tasks.merge(\n",
    "        df_unique_tasks_ratings[[\n",
    "            \"freq_mean\", \"freq_lower\", \"freq_upper\",\n",
    "            \"importance\", \"importance_lower\", \"importance_upper\",\n",
    "            \"relevance\", \"relevance_lower\", \"relevance_upper\",\n",
    "            \"task_normalized\", \"title_normalized\"\n",
    "        ]],\n",
    "        on=[\"task_normalized\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Merge on both title and task\n",
    "    merged_duplicate = df_duplicate_tasks.merge(\n",
    "        df_duplicate_tasks_ratings[[\n",
    "            \"freq_mean\", \"freq_lower\", \"freq_upper\",\n",
    "            \"importance\", \"importance_lower\", \"importance_upper\",\n",
    "            \"relevance\", \"relevance_lower\", \"relevance_upper\",\n",
    "            \"task_normalized\", \"title_normalized\"\n",
    "        ]],\n",
    "        on=[\"task_normalized\", \"title_normalized\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    merged = pd.concat([merged_unique, merged_duplicate], ignore_index=True)\n",
    "\n",
    "    # Replace placeholders with NaN\n",
    "    placeholder_values = [\"#\", \"*\", \"\", \"n/a\", \"na\", \"--\"]\n",
    "    merged.replace(placeholder_values, pd.NA, inplace=True)\n",
    "\n",
    "    # Drop fully empty columns\n",
    "    merged.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "    # Drop 'occ_code' and 'task_name'\n",
    "    merged.drop(columns=[\"occ_code\", \"task_name\", \"title_normalized\", \"title_normalized_x\", \"title_normalized_y\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Reorder columns: make 'task' and 'task_normalized' first\n",
    "    cols = merged.columns.tolist()\n",
    "    for col in [\"task_normalized\", \"task\"]:\n",
    "        if col in cols:\n",
    "            cols.insert(0, cols.pop(cols.index(col)))\n",
    "    merged = merged[cols]\n",
    "\n",
    "    return merged\n",
    "\n",
    "task_final = merge_all_and_cleanup(task_emp_wage_df, ratings_df)\n",
    "task_final.to_csv(\"../new_data/tasks_final.csv\", index=False)\n",
    "#display(task_final.reset_index(drop=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Helpers, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "# Put once at the TOP of your notebook/script (or just tweak this line)\n",
    "sns.set_context(\"notebook\", font_scale=1.0)  # was 1.2; smaller = less crowded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Pct Values In Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_df = pd.read_csv(\"../data/tasks_final.csv\")\n",
    "\n",
    "claude_userbase_bias = True\n",
    "\n",
    "if not claude_userbase_bias:\n",
    "    mask = main_df[\"major_occ_category\"] == \"Computer and Mathematical Occupations\"\n",
    "    main_df.loc[mask, \"pct_normalized\"] = 0\n",
    "    main_df[\"pct_normalized\"] = (main_df[\"pct_normalized\"] / main_df[\"pct_normalized\"].sum()) * 100\n",
    "\n",
    "# Create frequency adjusted pct\n",
    "main_df[f\"pct_freq_div_{2015}\"] = ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"]) / (main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"]).sum()) * 100\n",
    "main_df[f\"pct_freq_div_{2025}\"] = ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"]) / (main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"]).sum()) * 100\n",
    "\n",
    "# Create freq nat emp adjusted pct\n",
    "main_df[f\"pct_freq_nat_emp_div_{2015}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_nat_{2015}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_nat_{2015}\"]).sum()) * 100\n",
    "main_df[f\"pct_freq_nat_emp_div_{2024}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_nat_{2024}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_nat_{2024}\"]).sum()) * 100\n",
    "\n",
    "# Create freq ut emp adjusted pct\n",
    "main_df[f\"pct_freq_ut_emp_div_{2015}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_ut_{2015}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_ut_{2015}\"]).sum()) * 100\n",
    "main_df[f\"pct_freq_ut_emp_div_{2024}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_ut_{2024}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_ut_{2024}\"]).sum()) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Comp Pcts In Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "main_df[\"pct_claude_freq_nat_emp_2015\"] = ((main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_nat_2015\"]) / \n",
    "                                      (main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_nat_2015\"]).sum()) * 100\n",
    "main_df[\"pct_claude_freq_ut_emp_2015\"] = ((main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_ut_2015\"]) / \n",
    "                                     (main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_ut_2015\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "main_df[\"pct_claude_nat_emp_2015\"] = ((main_df[\"emp_tot_nat_2015\"]) / \n",
    "                                 (main_df[\"emp_tot_nat_2015\"]).sum()) * 100\n",
    "main_df[\"pct_claude_ut_emp_2015\"] = ((main_df[\"emp_tot_ut_2015\"]) / \n",
    "                                (main_df[\"emp_tot_ut_2015\"]).sum()) * 100\n",
    "\n",
    "\n",
    "#2024\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "main_df[\"pct_claude_freq_nat_emp_2024\"] = ((main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_nat_2024\"]) / \n",
    "                                      (main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_nat_2024\"]).sum()) * 100\n",
    "main_df[\"pct_claude_freq_ut_emp_2024\"] = ((main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_ut_2024\"]) / \n",
    "                                     (main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_ut_2024\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "main_df[\"pct_claude_nat_emp_2024\"] = ((main_df[\"emp_tot_nat_2024\"]) / \n",
    "                                 (main_df[\"emp_tot_nat_2024\"]).sum()) * 100\n",
    "main_df[\"pct_claude_ut_emp_2024\"] = ((main_df[\"emp_tot_ut_2024\"]) / \n",
    "                                (main_df[\"emp_tot_ut_2024\"]).sum()) * 100\n",
    "\n",
    "\n",
    "# Create comp column to pct_freq_nat_emp_div by have a base pct for each task\n",
    "main_df[\"pct_claude_base_dist\"] = (((1 / main_df[\"task_normalized\"].nunique()) / (main_df[\"n_occurrences\"])) /\n",
    "                       ((1 / main_df[\"task_normalized\"].nunique()) / (main_df[\"n_occurrences\"])).sum()) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Compt Pcts & Task Type In Eco Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eco 2015 df\n",
    "eco_df_2015 = pd.read_csv(\"../data/ratings_eco_2015.csv\")\n",
    "\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "eco_df_2015[\"pct_eco_freq_nat_emp_2015\"] = ((eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2015[\"pct_eco_freq_ut_emp_2015\"] = ((eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "eco_df_2015[\"pct_eco_nat_emp_2015\"] = ((eco_df_2015[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2015[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2015[\"pct_eco_ut_emp_2015\"] = ((eco_df_2015[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2015[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_nat_emp_div by have a base pct for each task\n",
    "eco_df_2015[\"task_counts\"] = eco_df_2015.groupby(\"task_normalized\")[\"task_normalized\"].transform(\"count\")\n",
    "eco_df_2015[\"pct_base_dist\"] = (((1 / eco_df_2015[\"task_normalized\"].nunique()) / (eco_df_2015[\"task_counts\"])) /\n",
    "                                ((1 / eco_df_2015[\"task_normalized\"].nunique()) / (eco_df_2015[\"task_counts\"])).sum()) * 100\n",
    "eco_df_2015[\"pct_eco_base_dist\"] = 1 / eco_df_2015[\"task_normalized\"].nunique()\n",
    "\n",
    "\n",
    "# eco 2015 df\n",
    "eco_df_2025 = pd.read_csv(\"../data/ratings_eco_2025.csv\")\n",
    "\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "eco_df_2025[\"pct_eco_freq_nat_emp_2024\"] = ((eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2025[\"pct_eco_freq_ut_emp_2024\"] = ((eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "eco_df_2025[\"pct_eco_nat_emp_2024\"] = ((eco_df_2025[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2025[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2025[\"pct_eco_ut_emp_2024\"] = ((eco_df_2025[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2025[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_nat_emp_div by have a base pct for each task\n",
    "eco_df_2025[\"task_counts\"] = eco_df_2025.groupby(\"task_normalized\")[\"task_normalized\"].transform(\"count\")\n",
    "eco_df_2025[\"pct_eco_base_dist\"] = (((1 / eco_df_2025[\"task_normalized\"].nunique()) / (eco_df_2025[\"task_counts\"])) /\n",
    "                                ((1 / eco_df_2025[\"task_normalized\"].nunique()) / (eco_df_2025[\"task_counts\"])).sum()) * 10\n",
    "\n",
    "\n",
    "\n",
    "def classify_task_type(df):\n",
    "    \"\"\"\n",
    "    Adds a 'task_type' column based on relevance and importance.\n",
    "    Core: relevance >= 67 AND importance >= 3.0\n",
    "    Supplemental: everything else\n",
    "    \"\"\"\n",
    "    conditions = [\n",
    "        (df[\"relevance\"] >= 67) & (df[\"importance\"] >= 3.0),   # Core\n",
    "    ]\n",
    "    choices = [\"Core\"]\n",
    "\n",
    "    df[\"task_type\"] = np.select(conditions, choices, default=\"Supplemental\")\n",
    "    return df\n",
    "\n",
    "# Apply to both\n",
    "eco_df_2015 = classify_task_type(eco_df_2015)\n",
    "eco_df_2025 = classify_task_type(eco_df_2025)\n",
    "\n",
    "# We need to merge the baseline data from the main_df into the eco_df dataframes so our logic in our main \n",
    "# loop can use the same df.\n",
    "eco_df_2015 = eco_df_2015.merge(main_df[[\"task_normalized\", \"pct_claude_base_dist\"]].drop_duplicates(), \n",
    "                                on=\"task_normalized\", how=\"left\")\n",
    "\n",
    "eco_df_2025 = eco_df_2025.merge(main_df[[\"task_normalized\", \"pct_claude_base_dist\"]].drop_duplicates(), \n",
    "                                on=\"task_normalized\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Tasks With Comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_tasks_with_comp_raw\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental if needed\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by task\n",
    "            agg = (sub.groupby(\"task_normalized\", as_index=False)[pct_col]\n",
    "                    .sum()\n",
    "                    .sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "\n",
    "            # --- map occupations to each task ---\n",
    "            task_to_titles = (\n",
    "                sub.groupby(\"task_normalized\")[\"title\"]\n",
    "                .apply(lambda x: sorted(set(x)))\n",
    "                .to_dict()\n",
    "            )\n",
    "\n",
    "            # add a new column with labels including up to 5 occupations\n",
    "            agg[\"task_with_occ\"] = agg[\"task_normalized\"].apply(\n",
    "                lambda t: (\n",
    "                    f\"{t}  [{', '.join(task_to_titles.get(t, [])[:3])}\"\n",
    "                    + (\"...\" if len(task_to_titles.get(t, [])) > 3 else \"\")\n",
    "                    + \"]\"\n",
    "                    if task_to_titles.get(t) else t\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to task level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (\n",
    "                    comp_sub.groupby(\"task_normalized\", as_index=False)[col_name]\n",
    "                    .sum()\n",
    "                    .rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                )\n",
    "                plot_df = plot_df.merge(eco_task, on=\"task_normalized\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"task_with_occ\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Tasks | {ttype} | {pct_col} | {scenario} | Raw\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Task [Occupations]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_tasks_unbiased_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_tasks_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Normalized Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_tasks_with_comp_norm\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental if needed\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by task\n",
    "            agg = (sub.groupby(\"task_normalized\", as_index=False)[pct_col]\n",
    "                    .sum())\n",
    "            # renormalize here\n",
    "            agg[pct_col] = agg[pct_col] / agg[pct_col].sum()\n",
    "\n",
    "            agg = (agg.sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "\n",
    "            # --- map occupations to each task ---\n",
    "            task_to_titles = (\n",
    "                sub.groupby(\"task_normalized\")[\"title\"]\n",
    "                .apply(lambda x: sorted(set(x)))\n",
    "                .to_dict()\n",
    "            )\n",
    "\n",
    "            # add a new column with labels including up to 5 occupations\n",
    "            agg[\"task_with_occ\"] = agg[\"task_normalized\"].apply(\n",
    "                lambda t: (\n",
    "                    f\"{t}  [{', '.join(task_to_titles.get(t, [])[:3])}\"\n",
    "                    + (\"...\" if len(task_to_titles.get(t, [])) > 3 else \"\")\n",
    "                    + \"]\"\n",
    "                    if task_to_titles.get(t) else t\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to task level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (comp_sub.groupby(\"task_normalized\", as_index=False)[col_name]\n",
    "                                .sum())\n",
    "                # renormalize here\n",
    "                eco_task[col_name] = eco_task[col_name] / eco_task[col_name].sum()\n",
    "\n",
    "                eco_task = eco_task.rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                plot_df = plot_df.merge(eco_task, on=\"task_normalized\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"task_with_occ\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Tasks | {ttype} | {pct_col} | {scenario} | Normalized\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Task [Occupations]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_tasks_unbiased_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_tasks_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Occupations With Comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_occupations_with_comp_raw\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by title\n",
    "            agg = (sub.groupby(\"title\", as_index=False)[pct_col]\n",
    "                    .sum()\n",
    "                    .sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "            \n",
    "            agg = agg.merge(sub[[\"title\", \"major_occ_category\"]].drop_duplicates(), on=\"title\", how=\"left\")\n",
    "\n",
    "            # add a new column with labels \n",
    "            agg[\"title_with_cat\"] = agg.apply(\n",
    "                lambda row: f\"{row['title']}  [{row['major_occ_category']}]\",\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to title level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (\n",
    "                    comp_sub.groupby(\"title\", as_index=False)[col_name]\n",
    "                    .sum()\n",
    "                    .rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                )\n",
    "                plot_df = plot_df.merge(eco_task, on=\"title\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"title_with_cat\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Occupations | {ttype} | {pct_col} | {scenario} | Raw\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Occupation [Major Occ Category]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_occupations_unbiased_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_occupations_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Normalized Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_occupations_with_comp_norm\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by task\n",
    "            agg = (sub.groupby(\"title\", as_index=False)[pct_col]\n",
    "                    .sum())\n",
    "            # renormalize here\n",
    "            agg[pct_col] = agg[pct_col] / agg[pct_col].sum()\n",
    "\n",
    "            agg = (agg.sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "            \n",
    "            agg = agg.merge(sub[[\"title\", \"major_occ_category\"]].drop_duplicates(), on=\"title\", how=\"left\")\n",
    "\n",
    "            # add a new column with labels \n",
    "            agg[\"title_with_cat\"] = agg.apply(\n",
    "                lambda row: f\"{row['title']}  [{row['major_occ_category']}]\",\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "\n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to title level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (comp_sub.groupby(\"title\", as_index=False)[col_name]\n",
    "                                .sum())\n",
    "                # renormalize here\n",
    "                eco_task[col_name] = eco_task[col_name] / eco_task[col_name].sum()\n",
    "\n",
    "                eco_task = eco_task.rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                plot_df = plot_df.merge(eco_task, on=\"title\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"title_with_cat\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Occupations | {ttype} | {pct_col} | {scenario} | Norm\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Occupation [Major Occ Category]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_occupations_unbiased_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_occupations_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

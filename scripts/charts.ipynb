{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Helpers, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "# Put once at the TOP of your notebook/script (or just tweak this line)\n",
    "sns.set_context(\"notebook\", font_scale=1.0)  # was 1.2; smaller = less crowded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Pct Values In Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_df = pd.read_csv(\"../data/tasks_final.csv\")\n",
    "\n",
    "claude_userbase_bias = True\n",
    "\n",
    "if not claude_userbase_bias:\n",
    "    mask = main_df[\"major_occ_category\"] == \"Computer and Mathematical Occupations\"\n",
    "    main_df.loc[mask, \"pct_normalized\"] = 0\n",
    "    main_df[\"pct_normalized\"] = (main_df[\"pct_normalized\"] / main_df[\"pct_normalized\"].sum()) * 100\n",
    "\n",
    "# Create frequency adjusted pct\n",
    "main_df[f\"pct_freq_div_{2015}\"] = ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"]) / (main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"]).sum()) * 100\n",
    "main_df[f\"pct_freq_div_{2025}\"] = ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"]) / (main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"]).sum()) * 100\n",
    "\n",
    "# Create freq nat emp adjusted pct\n",
    "main_df[f\"pct_freq_nat_emp_div_{2015}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_nat_{2015}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_nat_{2015}\"]).sum()) * 100\n",
    "main_df[f\"pct_freq_nat_emp_div_{2024}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_nat_{2024}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_nat_{2024}\"]).sum()) * 100\n",
    "\n",
    "# Create freq ut emp adjusted pct\n",
    "main_df[f\"pct_freq_ut_emp_div_{2015}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_ut_{2015}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2015}\"])/main_df[f\"emp_tot_ut_{2015}\"]).sum()) * 100\n",
    "main_df[f\"pct_freq_ut_emp_div_{2024}\"] = (((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_ut_{2024}\"]) / ((main_df[\"pct_normalized\"]/main_df[f\"freq_mean_{2025}\"])/main_df[f\"emp_tot_ut_{2024}\"]).sum()) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Comp Pcts In Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "main_df[\"pct_claude_freq_nat_emp_2015\"] = ((main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_nat_2015\"]) / \n",
    "                                      (main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_nat_2015\"]).sum()) * 100\n",
    "main_df[\"pct_claude_freq_ut_emp_2015\"] = ((main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_ut_2015\"]) / \n",
    "                                     (main_df[\"freq_mean_2015\"] * main_df[\"emp_tot_ut_2015\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "main_df[\"pct_claude_nat_emp_2015\"] = ((main_df[\"emp_tot_nat_2015\"]) / \n",
    "                                 (main_df[\"emp_tot_nat_2015\"]).sum()) * 100\n",
    "main_df[\"pct_claude_ut_emp_2015\"] = ((main_df[\"emp_tot_ut_2015\"]) / \n",
    "                                (main_df[\"emp_tot_ut_2015\"]).sum()) * 100\n",
    "\n",
    "\n",
    "#2024\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "main_df[\"pct_claude_freq_nat_emp_2024\"] = ((main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_nat_2024\"]) / \n",
    "                                      (main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_nat_2024\"]).sum()) * 100\n",
    "main_df[\"pct_claude_freq_ut_emp_2024\"] = ((main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_ut_2024\"]) / \n",
    "                                     (main_df[\"freq_mean_2025\"] * main_df[\"emp_tot_ut_2024\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "main_df[\"pct_claude_nat_emp_2024\"] = ((main_df[\"emp_tot_nat_2024\"]) / \n",
    "                                 (main_df[\"emp_tot_nat_2024\"]).sum()) * 100\n",
    "main_df[\"pct_claude_ut_emp_2024\"] = ((main_df[\"emp_tot_ut_2024\"]) / \n",
    "                                (main_df[\"emp_tot_ut_2024\"]).sum()) * 100\n",
    "\n",
    "\n",
    "# Create comp column to pct_freq_nat_emp_div by have a base pct for each task\n",
    "main_df[\"pct_claude_base_dist\"] = (((1 / main_df[\"task_normalized\"].nunique()) / (main_df[\"n_occurrences\"])) /\n",
    "                       ((1 / main_df[\"task_normalized\"].nunique()) / (main_df[\"n_occurrences\"])).sum()) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Compt Pcts & Task Type In Eco Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eco 2015 df\n",
    "eco_df_2015 = pd.read_csv(\"../data/ratings_eco_2015.csv\")\n",
    "\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "eco_df_2015[\"pct_eco_freq_nat_emp_2015\"] = ((eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2015[\"pct_eco_freq_ut_emp_2015\"] = ((eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2015[\"freq_mean\"] * eco_df_2015[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "eco_df_2015[\"pct_eco_nat_emp_2015\"] = ((eco_df_2015[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2015[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2015[\"pct_eco_ut_emp_2015\"] = ((eco_df_2015[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2015[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_nat_emp_div by have a base pct for each task\n",
    "eco_df_2015[\"task_counts\"] = eco_df_2015.groupby(\"task_normalized\")[\"task_normalized\"].transform(\"count\")\n",
    "eco_df_2015[\"pct_base_dist\"] = (((1 / eco_df_2015[\"task_normalized\"].nunique()) / (eco_df_2015[\"task_counts\"])) /\n",
    "                                ((1 / eco_df_2015[\"task_normalized\"].nunique()) / (eco_df_2015[\"task_counts\"])).sum()) * 100\n",
    "eco_df_2015[\"pct_eco_base_dist\"] = 1 / eco_df_2015[\"task_normalized\"].nunique()\n",
    "\n",
    "\n",
    "# eco 2015 df\n",
    "eco_df_2025 = pd.read_csv(\"../data/ratings_eco_2025.csv\")\n",
    "\n",
    "# Create comp column to pct_normalized by multiplying by freq and emp\n",
    "eco_df_2025[\"pct_eco_freq_nat_emp_2024\"] = ((eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2025[\"pct_eco_freq_ut_emp_2024\"] = ((eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2025[\"freq_mean\"] * eco_df_2025[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_div by only using emp\n",
    "eco_df_2025[\"pct_eco_nat_emp_2024\"] = ((eco_df_2025[\"tot_emp_nat\"]) / \n",
    "                                            (eco_df_2025[\"tot_emp_nat\"]).sum()) * 100\n",
    "eco_df_2025[\"pct_eco_ut_emp_2024\"] = ((eco_df_2025[\"tot_emp_ut\"]) / \n",
    "                                           (eco_df_2025[\"tot_emp_ut\"]).sum()) * 100\n",
    "\n",
    "# Create comp column to pct_freq_nat_emp_div by have a base pct for each task\n",
    "eco_df_2025[\"task_counts\"] = eco_df_2025.groupby(\"task_normalized\")[\"task_normalized\"].transform(\"count\")\n",
    "eco_df_2025[\"pct_eco_base_dist\"] = (((1 / eco_df_2025[\"task_normalized\"].nunique()) / (eco_df_2025[\"task_counts\"])) /\n",
    "                                ((1 / eco_df_2025[\"task_normalized\"].nunique()) / (eco_df_2025[\"task_counts\"])).sum()) * 10\n",
    "\n",
    "\n",
    "\n",
    "def classify_task_type(df):\n",
    "    \"\"\"\n",
    "    Adds a 'task_type' column based on relevance and importance.\n",
    "    Core: relevance >= 67 AND importance >= 3.0\n",
    "    Supplemental: everything else\n",
    "    \"\"\"\n",
    "    conditions = [\n",
    "        (df[\"relevance\"] >= 67) & (df[\"importance\"] >= 3.0),   # Core\n",
    "    ]\n",
    "    choices = [\"Core\"]\n",
    "\n",
    "    df[\"task_type\"] = np.select(conditions, choices, default=\"Supplemental\")\n",
    "    return df\n",
    "\n",
    "# Apply to both\n",
    "eco_df_2015 = classify_task_type(eco_df_2015)\n",
    "eco_df_2025 = classify_task_type(eco_df_2025)\n",
    "\n",
    "# We need to merge the baseline data from the main_df into the eco_df dataframes so our logic in our main \n",
    "# loop can use the same df.\n",
    "eco_df_2015 = eco_df_2015.merge(main_df[[\"task_normalized\", \"pct_claude_base_dist\"]].drop_duplicates(), \n",
    "                                on=\"task_normalized\", how=\"left\")\n",
    "\n",
    "eco_df_2025 = eco_df_2025.merge(main_df[[\"task_normalized\", \"pct_claude_base_dist\"]].drop_duplicates(), \n",
    "                                on=\"task_normalized\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Tasks With Comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_tasks_with_comp_raw\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental if needed\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by task\n",
    "            agg = (sub.groupby(\"task_normalized\", as_index=False)[pct_col]\n",
    "                    .sum()\n",
    "                    .sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "\n",
    "            # --- map occupations to each task ---\n",
    "            task_to_titles = (\n",
    "                sub.groupby(\"task_normalized\")[\"title\"]\n",
    "                .apply(lambda x: sorted(set(x)))\n",
    "                .to_dict()\n",
    "            )\n",
    "\n",
    "            # add a new column with labels including up to 5 occupations\n",
    "            agg[\"task_with_occ\"] = agg[\"task_normalized\"].apply(\n",
    "                lambda t: (\n",
    "                    f\"{t}  [{', '.join(task_to_titles.get(t, [])[:3])}\"\n",
    "                    + (\"...\" if len(task_to_titles.get(t, [])) > 3 else \"\")\n",
    "                    + \"]\"\n",
    "                    if task_to_titles.get(t) else t\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to task level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (\n",
    "                    comp_sub.groupby(\"task_normalized\", as_index=False)[col_name]\n",
    "                    .sum()\n",
    "                    .rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                )\n",
    "                plot_df = plot_df.merge(eco_task, on=\"task_normalized\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"task_with_occ\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Tasks | {ttype} | {pct_col} | {scenario} | Raw\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Task [Occupations]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_tasks_unbiased_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_tasks_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Normalized Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_tasks_with_comp_norm\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental if needed\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by task\n",
    "            agg = (sub.groupby(\"task_normalized\", as_index=False)[pct_col]\n",
    "                    .sum())\n",
    "            # renormalize here\n",
    "            agg[pct_col] = agg[pct_col] / agg[pct_col].sum()\n",
    "\n",
    "            agg = (agg.sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "\n",
    "            # --- map occupations to each task ---\n",
    "            task_to_titles = (\n",
    "                sub.groupby(\"task_normalized\")[\"title\"]\n",
    "                .apply(lambda x: sorted(set(x)))\n",
    "                .to_dict()\n",
    "            )\n",
    "\n",
    "            # add a new column with labels including up to 5 occupations\n",
    "            agg[\"task_with_occ\"] = agg[\"task_normalized\"].apply(\n",
    "                lambda t: (\n",
    "                    f\"{t}  [{', '.join(task_to_titles.get(t, [])[:3])}\"\n",
    "                    + (\"...\" if len(task_to_titles.get(t, [])) > 3 else \"\")\n",
    "                    + \"]\"\n",
    "                    if task_to_titles.get(t) else t\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to task level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (comp_sub.groupby(\"task_normalized\", as_index=False)[col_name]\n",
    "                                .sum())\n",
    "                # renormalize here\n",
    "                eco_task[col_name] = eco_task[col_name] / eco_task[col_name].sum()\n",
    "\n",
    "                eco_task = eco_task.rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                plot_df = plot_df.merge(eco_task, on=\"task_normalized\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"task_with_occ\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Tasks | {ttype} | {pct_col} | {scenario} | Normalized\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Task [Occupations]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_tasks_unbiased_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_tasks_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Occupations With Comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_occupations_with_comp_raw\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by title\n",
    "            agg = (sub.groupby(\"title\", as_index=False)[pct_col]\n",
    "                    .sum()\n",
    "                    .sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "            \n",
    "            agg = agg.merge(sub[[\"title\", \"major_occ_category\"]].drop_duplicates(), on=\"title\", how=\"left\")\n",
    "\n",
    "            # add a new column with labels \n",
    "            agg[\"title_with_cat\"] = agg.apply(\n",
    "                lambda row: f\"{row['title']}  [{row['major_occ_category']}]\",\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to title level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (\n",
    "                    comp_sub.groupby(\"title\", as_index=False)[col_name]\n",
    "                    .sum()\n",
    "                    .rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                )\n",
    "                plot_df = plot_df.merge(eco_task, on=\"title\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"title_with_cat\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Occupations | {ttype} | {pct_col} | {scenario} | Raw\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Occupation [Major Occ Category]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_occupations_unbiased_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_occupations_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Normalized Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_occupations_with_comp_norm\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by task\n",
    "            agg = (sub.groupby(\"title\", as_index=False)[pct_col]\n",
    "                    .sum())\n",
    "            # renormalize here\n",
    "            agg[pct_col] = agg[pct_col] / agg[pct_col].sum()\n",
    "\n",
    "            agg = (agg.sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "            \n",
    "            agg = agg.merge(sub[[\"title\", \"major_occ_category\"]].drop_duplicates(), on=\"title\", how=\"left\")\n",
    "\n",
    "            # add a new column with labels \n",
    "            agg[\"title_with_cat\"] = agg.apply(\n",
    "                lambda row: f\"{row['title']}  [{row['major_occ_category']}]\",\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "\n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to title level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (comp_sub.groupby(\"title\", as_index=False)[col_name]\n",
    "                                .sum())\n",
    "                # renormalize here\n",
    "                eco_task[col_name] = eco_task[col_name] / eco_task[col_name].sum()\n",
    "\n",
    "                eco_task = eco_task.rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                plot_df = plot_df.merge(eco_task, on=\"title\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"title_with_cat\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Occupations | {ttype} | {pct_col} | {scenario} | Norm\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Occupation [Major Occ Category]\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_occupations_unbiased_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_occupations_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Major Occ Category With Comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_major_occ_cat_with_comp_raw\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "\n",
    "            # aggregate by major_occ_category\n",
    "            agg = (sub.groupby(\"major_occ_category\", as_index=False)[pct_col]\n",
    "                    .sum()\n",
    "                    .sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "            \n",
    "            \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to title level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (\n",
    "                    comp_sub.groupby(\"major_occ_category\", as_index=False)[col_name]\n",
    "                    .sum()\n",
    "                    .rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                )\n",
    "                plot_df = plot_df.merge(eco_task, on=\"major_occ_category\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"major_occ_category\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Major Occ Cat | {ttype} | {pct_col} | {scenario} | Raw\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Major Occupation Category\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_major_occ_categories_unbiased_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_major_occ_categories_{pct_col}_{ttype.lower()}_{scenario}_raw.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Normalized Pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../charts/top_major_occ_cat_with_comp_norm\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "pcts = [\"pct_normalized\",\"pct_freq_div_2015\", \"pct_freq_div_2025\",\"pct_freq_nat_emp_div_2015\", \"pct_freq_nat_emp_div_2024\",\n",
    "        \"pct_freq_ut_emp_div_2015\", \"pct_freq_ut_emp_div_2024\"]\n",
    "task_types = [\"All\", \"Core\", \"Supplemental\"]\n",
    "\n",
    "econ_map = {\n",
    "    \"pct_normalized\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_freq_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_freq_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_freq_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_freq_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2015\": {\n",
    "        \"eco_comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_nat_emp_2015\", \"Nat 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_eco_ut_emp_2015\", \"UT 2015\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2015\", \"Nat AEI 2015\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2015\", \"UT AEI 2015\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_div_2025\": {\n",
    "        \"eco_comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_nat_emp_2024\", \"Nat 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_eco_ut_emp_2024\", \"UT 2024\"),\n",
    "        ],\n",
    "        \"aei_comp\": [\n",
    "            (\"main_df\", \"pct_claude_nat_emp_2024\", \"Nat AEI 2024\"),\n",
    "            (\"main_df\", \"pct_claude_ut_emp_2024\", \"UT AEI 2024\"),\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2015\": {\n",
    "        \"comp_2015\": [\n",
    "            (\"eco_df_2015\", \"pct_eco_base_dist\", \"Eco Base 2015\"),\n",
    "            (\"eco_df_2015\", \"pct_claude_base_dist\", \"Claude Base 2015\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_nat_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "    \"pct_freq_ut_emp_div_2024\": {\n",
    "        \"comp_2024\": [\n",
    "            (\"eco_df_2025\", \"pct_eco_base_dist\", \"Eco Base 2024\"),\n",
    "            (\"eco_df_2025\", \"pct_claude_base_dist\", \"Claude Base 2024\")\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "\n",
    "for pct_col in pcts:\n",
    "    if pct_col not in main_df.columns:\n",
    "        continue\n",
    "\n",
    "    for ttype in task_types:\n",
    "        if ttype == \"All\":\n",
    "            sub = main_df.copy()\n",
    "        else:\n",
    "            sub = main_df[main_df[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "        for scenario, baselines in econ_map.get(pct_col, {}).items():\n",
    "\n",
    "            # get the right dataframe objects for comp database (all tuples in this scenario share it)\n",
    "            df_lookup = {\n",
    "                \"main_df\": main_df,\n",
    "                \"eco_df_2015\": eco_df_2015,\n",
    "                \"eco_df_2025\": eco_df_2025,\n",
    "            }\n",
    "            df_name = baselines[0][0]\n",
    "            df_to_use_full = df_lookup[df_name]\n",
    "\n",
    "            # filter by Core/Supplemental\n",
    "            if ttype == \"All\":\n",
    "                comp_sub = df_to_use_full.copy()\n",
    "            else:\n",
    "                comp_sub = df_to_use_full[df_to_use_full[\"task_type\"].str.capitalize() == ttype]\n",
    "\n",
    "            # aggregate by major_occ_category\n",
    "            agg = (sub.groupby(\"major_occ_category\", as_index=False)[pct_col]\n",
    "                    .sum())\n",
    "            # renormalize here\n",
    "            agg[pct_col] = agg[pct_col] / agg[pct_col].sum()\n",
    "\n",
    "            agg = (agg.sort_values(pct_col, ascending=False)\n",
    "                    .head(top_n))\n",
    "            \n",
    "        \n",
    "            plot_df = agg.copy()\n",
    "            # 3) Economy baseline (sum econ pct to major_occ_category level, then merge)\n",
    "            for _, col_name, label in baselines:\n",
    "                eco_task = (comp_sub.groupby(\"major_occ_category\", as_index=False)[col_name]\n",
    "                                .sum())\n",
    "                # renormalize here\n",
    "                eco_task[col_name] = eco_task[col_name] / eco_task[col_name].sum()\n",
    "\n",
    "                eco_task = eco_task.rename(columns={col_name: f\"baseline_{label}\"})\n",
    "                plot_df = plot_df.merge(eco_task, on=\"major_occ_category\", how=\"left\")\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(figsize=(12, max(6, 0.55 * len(agg))))  # dynamic height\n",
    "            sns.barplot(data=agg, x=pct_col, y=\"major_occ_category\", color=\"skyblue\", ax=ax)\n",
    "\n",
    "            # Wrap y labels\n",
    "            current_labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "            wrapped_labels = ['\\n'.join(wrap(label, width=70)) for label in current_labels]\n",
    "            ax.set_yticks(ax.get_yticks())\n",
    "            ax.set_yticklabels(wrapped_labels, fontsize=7)\n",
    "            plt.subplots_adjust(left=0.45)  # more room for long task+occ labels\n",
    "\n",
    "            # Overlay economy baseline as a black line with a vertical end tick\n",
    "            # y positions are 0..n-1 in the plotted order\n",
    "            baseline_cols = [c for c in plot_df.columns if c.startswith(\"baseline_\")]\n",
    "\n",
    "            for i, row in plot_df.reset_index(drop=True).iterrows():\n",
    "                if len(baseline_cols) == 1:\n",
    "                    # single baseline → draw centered\n",
    "                    val = row[baseline_cols[0]]\n",
    "                    if pd.notna(val):\n",
    "                        ax.hlines(y=i, xmin=0, xmax=val, colors=\"black\", linewidth=1.5)\n",
    "                        ax.vlines(x=val, ymin=i-0.2, ymax=i+0.2, colors=\"black\", linewidth=1.5)\n",
    "                elif len(baseline_cols) == 2:\n",
    "                    # two baselines → offset vertically\n",
    "                    offsets = [-0.15, +0.15]   # shift up/down relative to center\n",
    "                    colors = [\"black\", \"red\"]  # Nat = black (top), UT = red (bottom)\n",
    "                    for (col, offset, color) in zip(baseline_cols, offsets, colors):\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            ax.hlines(y=i+offset, xmin=0, xmax=val, colors=color, linewidth=1.5)\n",
    "                            ax.vlines(x=val, ymin=i+offset-0.1, ymax=i+offset+0.1, colors=color, linewidth=1.5)\n",
    "\n",
    "            # Legend elements\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], color=\"black\", lw=1.5, label=\"National baseline\"),\n",
    "                Line2D([0], [0], color=\"red\", lw=1.5, label=\"Utah baseline (also AEI)\"),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "            # x-axis formatting\n",
    "            if agg[pct_col].max() <= 1.01:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x*100:.1f}%\"))\n",
    "                xlabel = f\"{pct_col} (percent)\"\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))\n",
    "                xlabel = pct_col\n",
    "\n",
    "            ax.set_title(f\"Top {top_n} Major Occ Cat | {ttype} | {pct_col} | {scenario} | Norm\", fontsize=14)\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "            ax.set_ylabel(\"Major Occupation Category\", fontsize=12)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if not claude_userbase_bias:\n",
    "                fname = f\"top{top_n}_major_occ_categories_unbiased_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "            else:\n",
    "                fname = f\"top{top_n}_major_occ_categories_{pct_col}_{ttype.lower()}_{scenario}_norm.png\"\n",
    "\n",
    "            plt.savefig(os.path.join(outdir, fname))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 major occ cat\n",
      "                                   major_occ_category  freq_mean_2025\n",
      "11                     Healthcare Support Occupations        4.232898\n",
      "10  Healthcare Practitioners and Technical Occupat...        3.959162\n",
      "9    Food Preparation and Serving Related Occupations        3.870816\n",
      "18                             Production Occupations        3.848581\n",
      "16      Office and Administrative Support Occupations        3.006120\n",
      "20                      Sales and Related Occupations        2.818507\n",
      "8          Farming, Fishing, and Forestry Occupations        2.751016\n",
      "21     Transportation and Material Moving Occupations        2.453087\n",
      "17              Personal Care and Service Occupations        2.432438\n",
      "2   Building and Grounds Cleaning and Maintenance ...        2.261683\n",
      "19                     Protective Service Occupations        2.162350\n",
      "1   Arts, Design, Entertainment, Sports, and Media...        2.054159\n",
      "13                                  Legal Occupations        2.049467\n",
      "12  Installation, Maintenance, and Repair Occupations        1.991470\n",
      "6             Construction and Extraction Occupations        1.738843\n",
      "4            Community and Social Service Occupations        1.520493\n",
      "3       Business and Financial Operations Occupations        1.310052\n",
      "7     Educational Instruction and Library Occupations        1.099295\n",
      "0            Architecture and Engineering Occupations        0.985837\n",
      "14     Life, Physical, and Social Science Occupations        0.959019\n",
      "5               Computer and Mathematical Occupations        0.947513\n",
      "15                             Management Occupations        0.872063\n",
      "2015 major occ cat\n",
      "                                   major_occ_category  freq_mean_2015\n",
      "11                     Healthcare Support Occupations        4.405847\n",
      "10  Healthcare Practitioners and Technical Occupat...        4.065709\n",
      "9    Food Preparation and Serving Related Occupations        4.010198\n",
      "18                             Production Occupations        3.532884\n",
      "16      Office and Administrative Support Occupations        2.929297\n",
      "21     Transportation and Material Moving Occupations        2.720943\n",
      "20                      Sales and Related Occupations        2.463698\n",
      "8          Farming, Fishing, and Forestry Occupations        2.371790\n",
      "17              Personal Care and Service Occupations        2.209104\n",
      "13                                  Legal Occupations        2.011500\n",
      "19                     Protective Service Occupations        2.009440\n",
      "12  Installation, Maintenance, and Repair Occupations        1.917735\n",
      "1   Arts, Design, Entertainment, Sports, and Media...        1.816741\n",
      "4            Community and Social Service Occupations        1.685752\n",
      "2   Building and Grounds Cleaning and Maintenance ...        1.663934\n",
      "6             Construction and Extraction Occupations        1.477648\n",
      "3       Business and Financial Operations Occupations        1.194510\n",
      "0            Architecture and Engineering Occupations        1.014892\n",
      "14     Life, Physical, and Social Science Occupations        0.992466\n",
      "7     Educational Instruction and Library Occupations        0.946250\n",
      "15                             Management Occupations        0.873066\n",
      "5               Computer and Mathematical Occupations        0.809644\n",
      "2025 occ\n",
      "                                             title  freq_mean_2025\n",
      "201                Diagnostic Medical Sonographers       10.105323\n",
      "408  Loading Machine Operators, Underground Mining       10.018049\n",
      "602                       Radiologic Technologists        9.342707\n",
      "64                                        Baristas        9.094430\n",
      "523                                   Optometrists        8.856900\n",
      "522                               Ophthalmologists        8.608115\n",
      "555                           Physician Assistants        8.589817\n",
      "94    Cardiovascular Technologists and Technicians        8.287819\n",
      "197                              Dental Hygienists        8.192690\n",
      "501                 Nuclear Medicine Technologists        7.898551\n",
      "2015 occ\n",
      "                                                 title  freq_mean_2015\n",
      "201                    Diagnostic Medical Sonographers       10.105323\n",
      "408      Loading Machine Operators, Underground Mining       10.018049\n",
      "197                                  Dental Hygienists        9.128585\n",
      "64                                            Baristas        9.094430\n",
      "162                                 Cooks, Short Order        8.716554\n",
      "170  Counter Attendants, Cafeteria, Food Concession...        8.312277\n",
      "94        Cardiovascular Technologists and Technicians        8.287819\n",
      "501                     Nuclear Medicine Technologists        7.898551\n",
      "602                           Radiologic Technologists        7.872444\n",
      "360                 Immigration and Customs Inspectors        7.798678\n"
     ]
    }
   ],
   "source": [
    "print(\"2025 major occ cat\")\n",
    "print(\n",
    "    main_df.groupby(\"major_occ_category\", as_index=False)[\"freq_mean_2025\"]\n",
    "           .mean()\n",
    "           .sort_values(\"freq_mean_2025\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"2015 major occ cat\")\n",
    "print(\n",
    "    main_df.groupby(\"major_occ_category\", as_index=False)[\"freq_mean_2015\"]\n",
    "           .mean()\n",
    "           .sort_values(\"freq_mean_2015\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"2025 occ\")\n",
    "print(\n",
    "    main_df.groupby(\"title\", as_index=False)[\"freq_mean_2025\"]\n",
    "           .mean()\n",
    "           .sort_values(\"freq_mean_2025\", ascending=False)\n",
    "           .head(10)\n",
    ")\n",
    "\n",
    "print(\"2015 occ\")\n",
    "\n",
    "print(\n",
    "    main_df.groupby(\"title\", as_index=False)[\"freq_mean_2015\"]\n",
    "           .mean()\n",
    "           .sort_values(\"freq_mean_2015\", ascending=False)\n",
    "           .head(10)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
